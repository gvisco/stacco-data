{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7018569",
   "metadata": {},
   "source": [
    "# What is this about?\n",
    "\n",
    "This Jupyter notebook is meant to explore the data collected from the **Stack Overflow Annual Developer Survey** (2021), with particular focus on the developers compensation. \n",
    "\n",
    "The dataset can be downloaded [here](https://insights.stackoverflow.com/survey).\n",
    "\n",
    "All the compensations are mapped to Euros thanks to this [Free Currency Rates API](https://github.com/fawazahmed0/currency-api)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff8a30",
   "metadata": {},
   "source": [
    "### Init (import libraries and define common functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def exists(name):\n",
    "    return name in locals() or name in globals()\n",
    "\n",
    "# initialize the conversion rates only once even if this cell gets executed multiple times\n",
    "if not exists('currencies'):\n",
    "    currencies = {}\n",
    "else:\n",
    "    print('Keeping the existing cache of currency conversion rates')\n",
    "\n",
    "\"\"\"One euro is equivalent to X in the other currency\"\"\"\n",
    "def euro_equivalent(c):\n",
    "    global currencies\n",
    "    c = c.lower()\n",
    "    if c in currencies:\n",
    "        return currencies[c]\n",
    "    else:\n",
    "        try:\n",
    "            url = \"https://cdn.jsdelivr.net/gh/fawazahmed0/currency-api@1/latest/currencies/eur/%s.json\" % c\n",
    "            res = urlopen(url)\n",
    "            data = json.loads(res.read())\n",
    "            conversion = data[c]\n",
    "            currencies[c] = conversion\n",
    "#             print(\"New currency: %s (%f)\" % (c, conversion))\n",
    "            return conversion\n",
    "        except:\n",
    "            return sys.float_info.max\n",
    "    \n",
    "\"\"\"Multiply the salary X times to get the yearly compensation\"\"\"\n",
    "def yearly_multiplier(freq):\n",
    "    return 48 if freq == 'Weekly' else 12 if freq == 'Monthly' else 1\n",
    "\n",
    "\"\"\"Remove the outliers from a dataframe based on the values of a single column.\n",
    "Keep only the rows that, for the specified column, have values in between the [qlow, qhigh] quantiles.\n",
    "\"\"\"\n",
    "def remove_outliers(df, column, qlow, qhigh):\n",
    "    low = df[column].quantile(qlow)\n",
    "    high = df[column].quantile(qhigh)\n",
    "#     print('Keeping only %s in [%f, %f]' % (column, low, high))\n",
    "    return df[(df[column] < high) & (df[column] > low)]\n",
    "\n",
    "\"\"\"Print markdown in output\"\"\"\n",
    "def print_md(s):\n",
    "    display(Markdown(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c77574",
   "metadata": {},
   "source": [
    "### Read and cleanup the dataset (it takes a while the first time, to download all the currency rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv (r'./resources/developer_survey_2021/survey_results_public.csv', \n",
    "                  usecols=['Country', 'Currency', 'CompTotal', 'CompFreq', 'YearsCodePro', 'OrgSize', 'Employment', 'MainBranch'])\n",
    "initsize = df.size\n",
    "print(\"Size after import: %f\" % initsize)\n",
    "\n",
    "# clean it up\n",
    "df = df.dropna()\n",
    "print(\"Size after NA filtering: %f (-%s wrt import)\" % (df.size, ((initsize - df.size) / initsize)))\n",
    "\n",
    "df['YearsCodePro'] = df['YearsCodePro'].map(lambda v: 0 if v == 'Less than 1 year' else 55 if v == 'More than 50 years' else int(v))\n",
    "\n",
    "# Keep only compensations that are reported as yearly total, as they seem more reliable (see Appendix)\n",
    "df = df[df.CompFreq == 'Yearly']\n",
    "print(\"Size after compensation filtering: %f (-%s wrt import)\" % (df.size, ((initsize - df.size) / initsize)))\n",
    "\n",
    "# Remove unknown organization size\n",
    "df = df[~df.OrgSize.str.startswith('I don')]\n",
    "print(\"Size after org size filtering: %f (-%s wrt import)\" % (df.size, ((initsize - df.size) / initsize)))\n",
    "\n",
    "df['OrgSize'] = df['OrgSize'].map(lambda v: '1 ' if v.startswith(\"Just me\") else v)\n",
    "df['OrgSizeIdx'] = df.apply(lambda row: int(row['OrgSize'][:row['OrgSize'].find(' ')].replace(',','')), axis=1)\n",
    "\n",
    "# Keep only full-time employed programmers\n",
    "df = df[df.Employment == 'Employed full-time']\n",
    "df = df[df.MainBranch == 'I am a developer by profession']\n",
    "print(\"Size after employment filtering: %f (-%s wrt import)\" % (df.size, ((initsize - df.size) / initsize)))\n",
    "\n",
    "# calculate yearly compensation in EUR\n",
    "df['Currency'] = df['Currency'].map(lambda s: str(s)[:3])\n",
    "df['EuroYearlyComp'] = df.apply(lambda row: row['CompTotal'] * yearly_multiplier(row['CompFreq']) / euro_equivalent(row['Currency']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def country_report(name, df):\n",
    "    print_md(\"## %s\" % name)\n",
    "    print_md(\"### Yearly Compensation (EUR)\")\n",
    "    quantiles = pd.DataFrame([[q, df['EuroYearlyComp'].quantile(q)] for q in [.05, .1, .25, .5, .75, .9, .95]], columns = ['Quantile', 'Comp.'])\n",
    "    print_md(quantiles.to_markdown(index=False))\n",
    "    points = remove_outliers(group,'EuroYearlyComp', .05, .95)\n",
    "    \n",
    "    bysize = df.groupby('OrgSizeIdx')\n",
    "    for orgsize, data in bysize:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(data['EuroYearlyComp'], data['YearsCodePro'], marker=\".\", linestyle=\"\", label=orgsize, alpha=.3)  \n",
    "        x1,x2,y1,y2 = plt.axis()  \n",
    "        plt.axis((0, 200000, 0, 60))\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "#     plt.plot(points['EuroYearlyComp'], points['YearsCodePro'], marker=\".\", linestyle=\"\", label=name, alpha=.3)\n",
    "#     x1,x2,y1,y2 = plt.axis()  \n",
    "#     plt.axis((0, 200000, 0, 60))\n",
    "#     plt.show()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5,3)\n",
    "groups = df.groupby('Country')\n",
    "for name, group in groups:\n",
    "    if group.size > 1000: # ignore countries with few data points\n",
    "        country_report(name, group)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d668581",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef239cab",
   "metadata": {},
   "source": [
    "## Are monthly and weekly compensation reliable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e778477a",
   "metadata": {},
   "source": [
    "### The outliers\n",
    "\n",
    "Monthly and weekly compensation appear to be often out of scale. This could happen, for example, if by mistake a yearly \n",
    "salary is marked as monthly or weekly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c1a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "adf = pd.read_csv (r'./resources/developer_survey_2021/survey_results_public.csv', \n",
    "                  usecols=['Country', 'Currency', 'CompTotal', 'CompFreq'])\n",
    "\n",
    "# remove NA\n",
    "adf = adf.dropna()\n",
    "\n",
    "# calculate yearly compensation in EUR\n",
    "adf['Currency'] = adf['Currency'].map(lambda s: str(s)[:3])\n",
    "adf['EuroYearlyComp'] = adf.apply(lambda row: row['CompTotal'] * yearly_multiplier(row['CompFreq']) / euro_equivalent(row['Currency']), axis=1)\n",
    "\n",
    "with_outliers = adf.groupby('CompFreq').size()\n",
    "\n",
    "frames = []\n",
    "for country, data in adf.groupby('Country'):\n",
    "    frames.append(remove_outliers(data, 'EuroYearlyComp', .05, .95))\n",
    "filtered = pd.concat(frames)\n",
    "\n",
    "without_outliers = filtered.groupby('CompFreq').size()\n",
    "\n",
    "result = pd.concat([with_outliers, without_outliers], axis=1, join=\"inner\")\n",
    "result['Removal rate'] = (result[0] - result[1]) / result[0]\n",
    "\n",
    "display(result.rename(columns={0: \"With outliers\", 1: \"Without outliers\"}))\n",
    "\n",
    "print_md(\"If we remove, for each country, the compensations below the .05 quantile and beyond the .95 quantile\" + \n",
    "        \"we end up removing a good deal of the weekly and monthly data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a7890",
   "metadata": {},
   "source": [
    "### Isn't monthly compensation too low?\n",
    "\n",
    "It seems also that monthly compensation is reported to be generally, and sometimes significantly, lower than yearly \n",
    "compensation. \n",
    "\n",
    "This is well visible esapecially in Western and Central European countries, like Austria, Belgium, France, Germany, Greece, Italy, Netherlands, Portugal, Spain, Switzerland.\n",
    "\n",
    "A possible explaination, to be verified, could be that the fiscal policy in these countries makes it harder to know \n",
    "or understand the exact compensation value before taxes, because taxes are subtracted upfront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983505c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "adf = pd.read_csv (r'./resources/developer_survey_2021/survey_results_public.csv', \n",
    "                  usecols=['Country', 'Currency', 'CompTotal', 'CompFreq', 'YearsCodePro'])\n",
    "\n",
    "# remove NA\n",
    "adf = adf.dropna()\n",
    "\n",
    "adf['YearsCodePro'] = adf['YearsCodePro'].map(lambda v: 0 if v == 'Less than 1 year' else 55 if v == 'More than 50 years' else int(v))\n",
    "\n",
    "# calculate yearly compensation in EUR\n",
    "adf['Currency'] = adf['Currency'].map(lambda s: str(s)[:3])\n",
    "adf['EuroYearlyComp'] = adf.apply(lambda row: row['CompTotal'] * yearly_multiplier(row['CompFreq']) / euro_equivalent(row['Currency']), axis=1)\n",
    "\n",
    "print_md(\"The graphs below show, for each country (excluding those with few data points) the yearly\" +\n",
    "         \" compensation in Euros vs the years of professional coding.\")\n",
    "print_md(\"The weekly/monthly/yearly compensation have different color.\")\n",
    "print_md(\"The lines are the linear regression, for each reported compensation frequency, that show the\" + \n",
    "         \" expected compensation increases with the years of professional coding\")\n",
    "\n",
    "for country, cdata in adf.groupby('Country'):\n",
    "    cdata = remove_outliers(cdata, 'EuroYearlyComp', .05, .9)\n",
    "    if cdata.size < 1000: # ignore countries with few data points\n",
    "        continue\n",
    "    print_md(\"#### %s\" % country)\n",
    "    fig = plt.figure()\n",
    "    for freq, fdata in cdata.groupby('CompFreq'):\n",
    "        if fdata.size < 150:\n",
    "            continue\n",
    "        plt.plot(fdata['YearsCodePro'], fdata['EuroYearlyComp'], marker=\".\", linestyle=\"\", label=freq, alpha=.3)\n",
    "        # linear regression\n",
    "        linear_regressor = LinearRegression() \n",
    "        X = fdata['YearsCodePro'].values.reshape(-1, 1)\n",
    "        Y = fdata['EuroYearlyComp'].values.reshape(-1, 1)\n",
    "        linear_regressor.fit(X, Y)\n",
    "        Y_pred = linear_regressor.predict(X)\n",
    "        plt.plot(X, Y_pred, label=freq)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c784a",
   "metadata": {},
   "source": [
    "### So? Are they reliable?\n",
    "\n",
    "Probably they are not very reliable in most cases, and especially if we are looking at Western and Central European countries. In fact, for many countries, the monthly and weekly data seem to add more noise than valuable information.\n",
    "\n",
    "However the number of datapoints marked as monthly/weekly makes around the 50% of the available dataset, and there are countries where the monthly data outnumbers greatly the yearly data. In these cases removing the monthly/weekly data might not be a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "adf = pd.read_csv (r'./resources/developer_survey_2021/survey_results_public.csv', \n",
    "                  usecols=['Country', 'CompFreq'])\n",
    "\n",
    "display(adf.groupby(['CompFreq']).size())\n",
    "\n",
    "world = []\n",
    "for country, data in adf.groupby('Country'):\n",
    "    if data.size < 1000: # ignore countries with few data points\n",
    "        continue\n",
    "    print_md('#### %s' % country)\n",
    "    data['CompFreq'].hist()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
